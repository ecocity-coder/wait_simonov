{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ6mxN2fivHl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pymorphy3\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "morph = pymorphy3.MorphAnalyzer()\n",
        "\n",
        "def read_poem(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        return [line.rstrip() for line in f if line.strip()]\n",
        "\n",
        "lines = read_poem('/content/ЖДИ_МЕНЯ.txt')\n",
        "\n",
        "def get_last_word(line):\n",
        "    words = re.findall(r'[а-яА-ЯёЁ]+', line)\n",
        "    return words[-1].lower() if words else None\n",
        "\n",
        "last_words = [get_last_word(line) for line in lines if get_last_word(line)]\n",
        "\n",
        "\n",
        "results = []\n",
        "for i, word in enumerate(last_words):\n",
        "    parses = morph.parse(word)\n",
        "    best = parses[0]\n",
        "\n",
        "\n",
        "    score = best.score\n",
        "\n",
        "\n",
        "    surprisal = -np.log10(score + 1e-12)\n",
        "\n",
        "    n_parses = len(parses)\n",
        "    pos_set = set(p.tag.POS for p in parses if p.tag.POS)\n",
        "    is_polysemic = n_parses > 1\n",
        "    is_homonymic = len(pos_set) > 1\n",
        "\n",
        "    results.append({\n",
        "        'line_idx': i + 1,\n",
        "        'word': word,\n",
        "        'score': score,\n",
        "        'surprisal': surprisal,\n",
        "        'n_parses': n_parses,\n",
        "        'is_polysemic': is_polysemic,\n",
        "        'is_homonymic': is_homonymic,\n",
        "        'pos_set': pos_set\n",
        "    })\n",
        "\n",
        "\n",
        "print(f\"{'Строка':<6} {'Слово':<12} {'Score':<10} {'Surprisal':<10} {'Полисемия':<10} {'Омонимия':<10}\")\n",
        "print(\"-\" * 75)\n",
        "for r in results:\n",
        "    print(f\"{r['line_idx']:<6} {r['word']:<12} {r['score']:<10.2e} {r['surprisal']:<10.2f} \"\n",
        "          f\"{'Да' if r['is_polysemic'] else 'Нет':<10} {'Да' if r['is_homonymic'] else 'Нет':<10}\")\n",
        "\n",
        "\n",
        "words_plot = [r['word'] for r in results]\n",
        "surprisal_plot = [r['surprisal'] for r in results]\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.bar(words_plot, surprisal_plot, color='darkred')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Surprisal (–log10(score))')\n",
        "plt.title('Оценка \"неожиданности\" последних слов строк (по pymorphy3.score)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\n Контраст с предыдущим словом (изменение части речи):\")\n",
        "for i, line in enumerate(lines):\n",
        "    words = re.findall(r'[а-яА-ЯёЁ]+', line)\n",
        "    if len(words) < 2:\n",
        "        continue\n",
        "    w1, w2 = words[-2].lower(), words[-1].lower()\n",
        "    p1 = morph.parse(w1)[0]\n",
        "    p2 = morph.parse(w2)[0]\n",
        "    if p1.tag.POS != p2.tag.POS:\n",
        "        print(f\"Стр. {i+1}: «{w1} ({p1.tag.POS}) → {w2} ({p2.tag.POS})»\")\n",
        "\n",
        "# Итог\n",
        "high_surprisal = [r['word'] for r in results if r['surprisal'] > 8]\n",
        "poly_words = [r['word'] for r in results if r['is_polysemic']]\n",
        "\n",
        "print(f\"\\n Выводы:\")\n",
        "print(f\"• Высокая 'неожиданность' (surprisal > 8): {high_surprisal}\")\n",
        "print(f\"• Полисемичные окончания: {poly_words}\")\n",
        "print(\"→ Конец строки действительно служит позицией для афористических и семантически насыщенных лексем.\")"
      ]
    }
  ]
}